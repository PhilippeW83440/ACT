#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\usepackage{algorithm,algpseudocode}

\usetheme{Warsaw}



\usepackage{tikz}
\usetikzlibrary{shapes, arrows}
\usetikzlibrary{er,positioning}
\tikzset{
    events/.style={ellipse, draw, align=center},
}

\usepackage{graphicx}
\usetikzlibrary{fit}
\usetikzlibrary{bayesnet}
\usepackage{pgfplots}

\usepackage{smartdiagram}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine biblatex
\cite_engine_type numerical
\biblio_style plain
\biblatex_bibstyle numeric
\biblatex_citestyle numeric
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Decision Making under Uncertainty for Autonomous Driving
\end_layout

\begin_layout Author
Philippe Weingertner
\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Autonomous Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
smartdiagramset{set color list={blue!30,green!30,green!30,red!30}, back
 arrow disabled=true}
\end_layout

\begin_layout Plain Layout


\backslash
smartdiagram[flow diagram:horizontal]{Sensors Fusion, Route and Behav.
 Planner, Motion Planner, Motion Control}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Autonomous Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Driving Strategy is a Sequential Decision Making problem:
\end_layout

\begin_deeper
\begin_layout Itemize
Strategic level: every e.g.
 a few seconds decide which maneuver to do
\end_layout

\begin_layout Itemize
Tactical level: every e.g.
 100 ms decide how to change 
\begin_inset Formula $a_{longitudinal},a_{lateral}$
\end_inset

 
\end_layout

\begin_layout Itemize
Trajectory can be seen as: 
\end_layout

\begin_deeper
\begin_layout Itemize
a set of spatio-temporal points 
\begin_inset Formula $\{x_{i},y_{i},t_{i}\}_{1..N}$
\end_inset

 
\end_layout

\begin_layout Itemize
or a starting point with a set of accelerations every time steps 
\begin_inset Formula $\{\ddot{x}_{i},\ddot{y}_{i}\}_{1..N}$
\end_inset

 
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Route planner: long-term decisions
\end_layout

\begin_layout Itemize
Behavioral planner: mid-tem decisions
\end_layout

\begin_layout Itemize
Motion planner: short-term decisions
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Autonomous Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Multiple sources of Uncertainty:
\end_layout

\begin_deeper
\begin_layout Itemize
sensors uncertainty
\end_layout

\begin_layout Itemize
occlusions
\end_layout

\begin_layout Itemize
other agents behaviors
\end_layout

\end_deeper
\begin_layout Itemize
Conflicting objectives:
\end_layout

\begin_deeper
\begin_layout Itemize
efficiency: Time To Goal
\end_layout

\begin_layout Itemize
comfort: low jerk
\end_layout

\begin_layout Itemize
safety: safety distances
\end_layout

\end_deeper
\begin_layout Itemize
How to make good decisions dealing with multiple sources of uncertainty
 and satisfying conflicting objectives ?
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Rationale Decision Making
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Rationale Decision Making is reasoning about uncertainty and objectives
\end_layout

\begin_deeper
\begin_layout Itemize
Uncertainty: a Bayesian Network models uncertainties and dependencies.
 It is a joint distribution model.
\end_layout

\begin_layout Itemize
Objectives: define a utility function (or value function or Q function)
 which corresponds to our preferences (efficiency, comfort, safety...)
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Uncertainty: Probabilities and Bayes Rule
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Definition of Conditional Probability: 
\begin_inset Formula $P(A\mid B)=\frac{P(A,B)}{P(B)}$
\end_inset


\end_layout

\begin_layout Itemize
Law of Total Probability:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $P(A)=\underset{B\in\mathcal{B}}{\sum}P(A,B)=\underset{B\in\mathcal{B}}{\sum}P(A\mid B)P(B)$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $P(A\mid C)=\underset{B\in\mathcal{B}}{\sum}P(A,B\mid C)=\underset{B\in\mathcal{B}}{\sum}P(A\mid B,C)P(B\mid C)$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Bayes Rule: 
\begin_inset Formula $P(State\mid Obs)=\frac{P(O\mid S)P(S)}{P(O)}\propto P(O\mid S)P(S)$
\end_inset


\end_layout

\begin_layout Itemize
Bayesian Network is a compact representation of joint distribution
\end_layout

\begin_deeper
\begin_layout Itemize

\color red
\begin_inset Formula $\boxed{P(E\mid B,S)\text{ has }(n_{E}-1)\times n_{B}\times n_{S}\text{ independant params}}$
\end_inset


\end_layout

\begin_layout Itemize
BN chain rule: 
\begin_inset Formula $P(x_{1},\ldots,x_{n})=\prod_{i=1}^{n}P(x_{i}\mid pa_{x_{i}})$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Uncertainty: Bayesian Network
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Compact representation of a joint distribution
\end_layout

\begin_layout Itemize
Inference: find a distribution over some unobserved variables given a set
 of observed variables.
 It might be used when the structure and parameters of the Bayesian network
 are known
\end_layout

\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Exact Inference
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance=0.4cm, >=stealth'] 
\end_layout

\begin_layout Plain Layout


\backslash
node (A) [events] {A};
\end_layout

\begin_layout Plain Layout


\backslash
node (C) [events, below right = of A] {C};
\end_layout

\begin_layout Plain Layout


\backslash
node (B) [events, above right = of C] {B};
\end_layout

\begin_layout Plain Layout


\backslash
node (D) [events, right = of C] {D};
\end_layout

\begin_layout Plain Layout


\backslash
node (E) [events, right = of D] {E};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (A) -- (C); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (B) -- (C); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (B) -- (D); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (D) -- (E); 
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $P(a^{1}\mid b^{1},d^{1})=\frac{P(a^{1},b^{1},d^{1})}{P(b^{1},d^{1})}$
\end_inset

 by definition of Cond Prob
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $P(a^{1},b^{1},d^{1})=\sum_{c}\sum_{e}P(a^{1},b^{1},c,d^{1},e)$
\end_inset

 by Law of Tot Prob
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $P(a^{1},b^{1},c,d^{1},e)=P(a^{1})\mathbf{P(b^{1})P(d^{1}\mid b^{1})}P(c\mid a^{1},b^{1})P(e\mid d)$
\end_inset

 by BN
\end_layout

\begin_layout Plain Layout
We sum over unobserved variables
\end_layout

\begin_layout Plain Layout
4 summations for numerator
\end_layout

\begin_layout Plain Layout
8 summations for denominator (but 
\series bold
simplification
\series default
 here)
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Uncertainty: Example of a Bayesian Network, Kalman Filter
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Inference for Temporal Models: HMM, Kalman Filter ...
 
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance=0.2cm, >=stealth'] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
node (St) [events] {$s_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Sprev) [events, left = of St] {$s_{t-1}$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Snext) [events, right = of St] {$s_{t+1}$};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
node (Ot) [events, below = of St] {$o_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Oprev) [events, below = of Sprev] {$o_{t-1}$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Onext) [events, below = of Snext] {$o_{t+1}$};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
node (Sstart) [left = of Sprev] {$...$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Send)   [right = of Snext] {$...$};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (Sstart) -- (Sprev); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (Sprev) -- (St); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (St) -- (Snext); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (Snext) -- (Send); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (Sprev) -- (Oprev);
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (St) -- (Ot);
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (Snext) -- (Onext);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
Filtering problem: 
\begin_inset Formula $P(S_{t}\mid O_{0:t})$
\end_inset

 ?
\end_layout

\begin_layout Plain Layout
By Bayes rule, d-sep, Law of Total Probability
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $P(s_{t}\mid o_{_{0:t}})=P(s_{t}\mid o_{t},o_{_{0:t-1}})\propto P(o_{t}\mid s_{t},o_{_{0:t-1}})P(s_{t}\mid o_{_{0:t-1}})$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\mathbf{P(s_{t}\mid o_{_{0:t}})\propto P(o_{t}\mid s_{t})\sum_{s_{t-1}}P(s_{t}\mid s_{t-1})P(s_{t-1}\mid o_{_{0:t-1}})}$
\end_inset

 
\end_layout

\begin_layout Plain Layout
With continuous variables replace 
\begin_inset Formula $\sum$
\end_inset

 with 
\begin_inset Formula $\int$
\end_inset


\end_layout

\begin_layout Plain Layout
Our known model is:
\end_layout

\begin_layout Itemize
Observation model: 
\begin_inset Formula $P(o_{t}\mid s_{t})$
\end_inset


\end_layout

\begin_layout Itemize
State transition model: 
\begin_inset Formula $P(s_{t}\mid s_{t-1})$
\end_inset


\end_layout

\begin_layout Plain Layout
So we get a 
\series bold
recursive formula
\series default
 about our belief 
\begin_inset Formula $b_{t}(s)$
\end_inset

 based on all possible previous states belief 
\begin_inset Formula $b_{t-1}(s')$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Uncertainty: Recursive Bayesian Estimation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Recursive Bayesian Estimation
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
Function{RecursiveBayesianEstimation}{} 
\end_layout

\begin_layout Plain Layout

	
\backslash
State $b_0(s) 
\backslash
gets P(o_0 
\backslash
mid s)P(s_0) 
\backslash
text{ for all }s$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $
\backslash
text{Normalize }b_0$
\end_layout

\begin_layout Plain Layout

	
\backslash
For{$t 
\backslash
gets 1
\backslash
text{ to }
\backslash
infty$} 
\end_layout

\begin_layout Plain Layout

		
\backslash
State $b_t(s) 
\backslash
gets P(o_{t}
\backslash
mid s)
\backslash
sum_{s'}P(s 
\backslash
mid s')b_{t-1}(s')
\backslash
text{ for all s}$
\end_layout

\begin_layout Plain Layout

		
\backslash
State $
\backslash
text{Normalize }b_t$
\end_layout

\begin_layout Plain Layout

	
\backslash
EndFor
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Objectives: Utility or Value function
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
We define a utility related to preferences (or objectives or costs) so that
 it follows 4 axioms
\end_layout

\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout

\series bold
Constraints on Rational Preferences
\series default

\begin_inset Newline newline
\end_inset


\shape italic
Completeness
\shape default
: we can compare them 
\begin_inset Formula $A\succ B,A\prec B,A\sim B$
\end_inset


\end_layout

\begin_layout Plain Layout

\shape italic
Transitivity
\shape default
: 
\begin_inset Formula $A\succeq B,B\succeq C\Rightarrow A\succeq C$
\end_inset


\end_layout

\begin_layout Plain Layout

\shape italic
Continuity
\shape default
: 
\begin_inset Formula $A\succeq C\succeq B\Rightarrow\exists p\text{ s.t. }\left[A:p;B:1-p\right]\sim C$
\end_inset

 
\end_layout

\begin_layout Plain Layout
translated to 
\begin_inset Formula $\boxed{{pU(A)+(1-p)U(B)=U(C)}}$
\end_inset

 
\end_layout

\begin_layout Plain Layout

\shape italic
Independence
\shape default
: 
\begin_inset Formula $A\succ B\Rightarrow\forall(C,p),\left[A:p;C:1-p\right]\succ\left[B:p;C:1-p\right]$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Objectives: Maximum Expected Utility principle
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Bayesian Network + Utility 
\begin_inset Formula $\Longrightarrow$
\end_inset

 Decision Network 
\end_layout

\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Maximum Expected Utility Principle
\series default

\begin_inset Newline newline
\end_inset


\shape italic

\begin_inset Formula $E[U(a\mid o)]=\sum_{s'}P(s'\mid a,o)U(s')$
\end_inset


\end_layout

\begin_layout Plain Layout
A rational agent chooses 
\begin_inset Formula $a^{*}=\underset{a}{argmax}\left.E[U(a\mid o)]\right.$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Network: example
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Evaluating Decision Networks
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{minipage}{0.4
\backslash
linewidth}
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{c c c} 
\end_layout

\begin_layout Plain Layout

 T & D  & U(T,D) 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline  
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

  0 & 0  & 0 
\backslash

\backslash
   
\end_layout

\begin_layout Plain Layout

  0 & 1  & -10 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

  1 & 0  & -1 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

  1 & 1  & -1 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout


\backslash
end{minipage}
\end_layout

\begin_layout Plain Layout


\backslash
begin{minipage}{0.4
\backslash
linewidth}
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance=0.5cm, >=stealth'] 
\end_layout

\begin_layout Plain Layout


\backslash
node (T) [events, rectangle, label=left:{Treat?}] {$T$};
\end_layout

\begin_layout Plain Layout


\backslash
node (D) [events, below = of T, label=left:{Disease?}] {$D$};
\end_layout

\begin_layout Plain Layout


\backslash
node (U) [events, diamond, right = of D] {$U$};
\end_layout

\begin_layout Plain Layout


\backslash
node (O1) [events, below left = of D] {$O_1$};
\end_layout

\begin_layout Plain Layout


\backslash
node (O2) [events, below = of D] {$O_2$};
\end_layout

\begin_layout Plain Layout


\backslash
node (O3) [events, below right = of D] {$O_3$};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (D) -- (O1); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (D) -- (O2); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (D) -- (O3); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (D) -- (U); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (T) -- (U); 
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout


\backslash
end{minipage}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $E[U(a\mid o)]=\sum_{s'}P(s'\mid a,o)U(s')$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $s'$
\end_inset

 represents an instanciation of the nodes in the decision network
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $E[U(t^{1}\mid o_{1}^{1})]=\sum_{d}P(d\mid t^{1},o_{1}^{1})U(t^{1},d)$
\end_inset


\end_layout

\begin_layout Plain Layout
Then any inference method can be used to evaluate 
\begin_inset Formula $P(d\mid t^{1},o_{1}^{1})$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\Longrightarrow$
\end_inset


\series bold
Inference pb: what is the distribution of the variables that are parents
 to the utility node ?
\end_layout

\begin_layout Plain Layout
To decide whether to apply a treatment compare 
\begin_inset Formula $E[U(t^{1}\mid o_{1}^{1})]$
\end_inset

 vs 
\begin_inset Formula $E[U(t^{0}\mid o_{1}^{1})]$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
MDP: Markov Decision Process
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
MDP 
\begin_inset Formula $<\mathcal{S},\mathcal{A},T,R>$
\end_inset

 stationary representation
\end_layout

\begin_layout Plain Layout
Markov assumption: current state only depends on your previous state and
 the action you took to get there
\end_layout

\begin_layout Plain Layout
Stationary: 
\begin_inset Formula $T,R$
\end_inset

 do not change with time
\end_layout

\begin_layout Plain Layout
Decision Network but with 
\begin_inset Formula $P(S_{t+1}\mid S_{t},A_{t})$
\end_inset

 and 
\begin_inset Formula $P(R_{t}\mid A_{t},S_{t})$
\end_inset

, not stationary, in the general case 
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance=0.4cm, >=stealth'] 
\end_layout

\begin_layout Plain Layout


\backslash
node (A) [events, rectangle, scale=0.75] {$A_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (R) [events, diamond, scale=0.6, below = of A] {$R_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (S) [events, scale=0.75, below = of R] {$S_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Snext) [events, circle, scale=0.75, right = of S] {$S_{t+1}$};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (A) -- (R); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (S) -- (R); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (S) -- (Snext); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (A) -- (Snext);
\end_layout

\begin_layout Plain Layout


\backslash
draw [->, bend left, dotted] (S.west) to (A.west); 
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $R(s,a)$
\end_inset

: expected reward received when executing action 
\begin_inset Formula $a$
\end_inset

 from state 
\begin_inset Formula $s$
\end_inset

.
 Here we assume it is a deterministic function (but not required).
\end_layout

\begin_layout Plain Layout
Utility function decomposed into rewards 
\begin_inset Formula $R_{0:t}$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
POMDP: Partially Observable Markov Decision Process
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
POMDP: 
\begin_inset Formula $<\mathcal{S},\mathcal{A},\mathcal{O},T,R,O>$
\end_inset


\end_layout

\begin_layout Plain Layout
MDP + set of observations 
\begin_inset Formula $\mathcal{O}$
\end_inset

 + observation model 
\begin_inset Formula $O$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[node distance=0.4cm, >=stealth'] 
\end_layout

\begin_layout Plain Layout


\backslash
node (A) [events, rectangle, scale=0.75] {$A_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (R) [events, diamond, scale=0.6, below = of A] {$R_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (S) [events, scale=0.75, below = of R] {$S_t$};
\end_layout

\begin_layout Plain Layout


\backslash
node (Snext) [events, circle, scale=0.75, right = of S] {$S_{t+1}$};
\end_layout

\begin_layout Plain Layout


\backslash
node (O) [events, scale=0.75, color=magenta, below = of S] {$O_t$};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (A) -- (R); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (S) -- (R); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (S) -- (Snext); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (S) -- (O); 
\end_layout

\begin_layout Plain Layout


\backslash
draw [->] (A) -- (Snext);
\end_layout

\begin_layout Plain Layout


\backslash
draw [->, bend left, dotted] (S.west) to (A.west); 
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
The proba of observing 
\begin_inset Formula $o$
\end_inset

 given state 
\begin_inset Formula $s$
\end_inset

 is written
\series bold
 
\begin_inset Formula $\mathbf{O(o\mid s)}$
\end_inset

 
\end_layout

\begin_layout Plain Layout
The decision in a POMDP at time 
\begin_inset Formula $t$
\end_inset

 can only be based on the history of observations 
\begin_inset Formula $o_{1:t}$
\end_inset


\end_layout

\begin_layout Plain Layout
Instead of keeping track of arbitrarily long histories, we keep track of
 the belief state
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $b(s)$
\end_inset

 is the probability assigned to being in state 
\begin_inset Formula $s$
\end_inset

 
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Policy
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Determines action given past history of states and actions 
\begin_inset Formula $a=\pi_{t}(h_{t})=\pi_{t}(s_{0:t},a_{0:t-1})$
\end_inset


\end_layout

\begin_layout Itemize
But with MDP we just care about current state as 
\begin_inset Formula $s_{t}$
\end_inset

 d-separates past from future
\end_layout

\begin_layout Itemize
\begin_inset Formula $\Longrightarrow$
\end_inset

 
\begin_inset Formula $\pi_{t}(s_{t})$
\end_inset

 or 
\begin_inset Formula $\pi(s_{t})$
\end_inset

 if the policy is stationary
\end_layout

\begin_layout Itemize
If states and actions are discrete: it is just a matrix specifying what
 action to do in a specific state.
 A Policy can be deterministic or stochastic
\end_layout

\begin_layout Itemize
An optimal policy 
\begin_inset Formula $\pi^{*}$
\end_inset

 is a policy that maximizes expected utility: 
\begin_inset Formula $\pi^{*}(s)=\underset{\pi}{argmax}\;U^{\pi}(s)$
\end_inset

 for all states 
\begin_inset Formula $s$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Bellman Equations
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout

\series bold
\shape italic
\color blue
Bellman Equations
\end_layout

\begin_layout Plain Layout

\series bold
\shape italic
\color blue
\begin_inset Formula $U_{k}^{*}(s)=\underset{a}{max}\:[R(s,a)+\gamma\sum_{s'}T(s'\mid s,a)U_{k-1}^{*}(s')]$
\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\shape italic
\color blue
\begin_inset Formula $\pi^{*}(s)=\underset{a}{argmax}\:[R(s,a)+\gamma\sum_{s'}T(s'\mid s,a)U^{*}(s')]$
\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\color red
\begin_inset Formula $U^{*}(s)=\underset{a}{max}\:[R(s,a)+\gamma\sum_{s'}T(s'\mid s,a)U^{*}(s')]$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
How to find a Policy ?
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Dynamic Programming: small states and actions spaces, known Transition and
 Reward models.
\end_layout

\begin_deeper
\begin_layout Itemize
Policy Iteration or Value Iteration algorithms can compute the 
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
optimal
\end_layout

\end_inset

 policy (it is proven) 
\end_layout

\end_deeper
\begin_layout Itemize
Approximate Dynamic Programming: when states and/or actions spaces are big
 or continuous
\end_layout

\begin_deeper
\begin_layout Itemize
Local Approximation
\end_layout

\begin_layout Itemize
Global Approximation
\end_layout

\end_deeper
\begin_layout Itemize
Reinforcement Learning: 
\end_layout

\begin_deeper
\begin_layout Itemize
Model-Based: 
\begin_inset Formula $T,R$
\end_inset

 are estimated first (learned from data, Maximum Likelihood for example
 or derived from Expert knowledge) and then we derive a policy
\end_layout

\begin_layout Itemize
Model-Free: 
\begin_inset Formula $T,R$
\end_inset

 unknown.
 We try to derive directly the policy by interacting and observing rewards.
 It usually requires a simulator to avoid real word experimentation.
\end_layout

\end_deeper
\begin_layout Itemize
Online Methods: do not compute a policy for the entire state space offline.
 Restrict computation to states reachable from current state
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Reinforcement Learning Model-Based
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Estimate 
\begin_inset Formula $T,R,O$
\end_inset

 models.
 From data or by expert knowledge or a combination ...
\end_layout

\begin_layout Itemize
Offline methods:
\end_layout

\begin_deeper
\begin_layout Itemize
Policy Iteration or Value Iteration based
\end_layout

\end_deeper
\begin_layout Itemize
Online methods:
\end_layout

\begin_deeper
\begin_layout Itemize
Forward Search, Branch and Bound Search
\end_layout

\begin_layout Itemize
Sparse Sampling, MCTS (Monte Carlo Tree Search)
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Reinforcement Learning Model-Free
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Incremental Estimation
\end_layout

\begin_layout Plain Layout
X a random variable, try to estimate the mean: 
\begin_inset Formula $\mu=\mathbb{E}[X]$
\end_inset


\end_layout

\begin_layout Plain Layout
With samples 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\hat{x}_{n}=\frac{1}{n}\sum_{i=1}^{n}x_{i}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\Longleftrightarrow\hat{x}_{n}=\hat{x}_{n-1}+\frac{1}{n}(x_{n}-\hat{x}_{n-1})$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\hat{x}\gets\hat{x}+\alpha\left(n\right)$
\end_inset


\begin_inset Formula $\left(x-\hat{x}\right)$
\end_inset

 
\end_layout

\begin_layout Plain Layout

\series bold
\color blue
Key equation in Temporal Difference Learning
\end_layout

\begin_layout Plain Layout

\series bold
\color blue
\begin_inset Formula $\hat{x}\gets\hat{x}+\alpha$
\end_inset


\begin_inset Formula $\left(x-\hat{x}\right)$
\end_inset

 
\end_layout

\begin_layout Plain Layout
With 
\begin_inset Formula $x$
\end_inset

 new meas and 
\begin_inset Formula $\hat{x}$
\end_inset

 current estimate
\end_layout

\begin_layout Plain Layout
Temporal difference error: 
\begin_inset Formula $x-\hat{x}$
\end_inset

 is the difference between a sample and our previous estimate
\end_layout

\begin_layout Plain Layout
Constant LR 
\begin_inset Formula $\Rightarrow$
\end_inset

 decays the influence of past samples exponentially
\end_layout

\begin_layout Plain Layout
And as we collect experience, more recent examples based on better 
\begin_inset Formula $Q$
\end_inset

 , are better
\end_layout

\begin_layout Plain Layout
A larger LR means new samples have a greater effect on the current estimate
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Reinforcement Learning Model-Free
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 1
use_makebox 0
width "97col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
Q-learning
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $Q(s,a)=R(s,a)+\gamma\:\sum_{s'}T(s'\mid s,a)U(s')$
\end_inset

 
\end_layout

\begin_layout Plain Layout
With 
\begin_inset Formula $U(s')=\underset{a'}{max\:}Q(s',a')$
\end_inset


\end_layout

\begin_layout Plain Layout

\color teal
How to update 
\begin_inset Formula $Q$
\end_inset

 directly after we observe 
\begin_inset Formula $r$
\end_inset

 and 
\begin_inset Formula $s'$
\end_inset

 ?
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $Q(s,a)\gets Q(s,a)+\alpha\left(\mathbf{r+\gamma\:\underset{a'}{max}\:Q(s',a')}-Q(s,a)\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
This update + good exploration strategy 
\begin_inset Formula $\Rightarrow Q(s,a)\rightarrow Q^{*}(s,a)$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Urban Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
smartdiagramset{set color list={blue!30,green!30,green!30,red!30}, back
 arrow disabled=true}
\end_layout

\begin_layout Plain Layout


\backslash
smartdiagram[flow diagram:horizontal]{Sensors Fusion, Route and Behav.
 Planner, Motion Planner, Motion Control}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty: Volvo Trucks Thesis
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Graphics
	filename img/volvo1.png
	lyxscale 30
	scale 30

\end_inset


\begin_inset Graphics
	filename img/volvo2.png
	lyxscale 30
	scale 30

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Urban Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Graphics
	filename img/AnticolisionTests.png
	lyxscale 50
	scale 50

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Urban Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
States
\end_layout

\end_inset

: 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
{(x,y,v_x,v_y)_{ego},{(x,y,v_x,v_y)_{obj}}_{1..n}
\backslash
}$
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
Actions
\end_layout

\end_inset

: 
\begin_inset ERT
status open

\begin_layout Plain Layout

$a_{longitudinal} 
\backslash
in [-2, -1, 0, 1, 2]$ $m.s^{-2}$
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Follow a lane, think in Frenet coordinates and control 
\begin_inset Formula $a_{longitudinal}$
\end_inset


\end_layout

\begin_layout Itemize
Define a path for a lane change and control acceleration along that path
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
Observations
\end_layout

\end_inset

: States observed via a sensor 
\end_layout

\begin_layout Itemize
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
Transition model
\end_layout

\end_inset

: Linear Gaussian Dynamics, Kalman filter type with 
\begin_inset Formula $T(s'\mid s,a)=\mathcal{N}(s'\mid T_{s}s+T_{a}a,\Sigma_{s})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
Observation model
\end_layout

\end_inset

: Linear Gaussian Observation sensor model 
\begin_inset Formula $O(o\mid s')=\mathcal{N}(o\mid O_{s}s',\Sigma_{o})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Flex Bold
status open

\begin_layout Plain Layout
Reward model
\end_layout

\end_inset

: accounts for efficiency (Time To Goal), comfort (Hard Braking) and safety
 (Time To Collision)
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Urban Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Transition model: Linear Gaussian Dynamics, Kalman filter type with 
\begin_inset Formula $T(s'\mid s,a)=\mathcal{N}(s'\mid T_{s}s+T_{a}a,\Sigma_{s})$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $s'=\begin{bmatrix}1 & 0 & dt & 0\\
0 & 1 & 0 & dt\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1
\end{bmatrix}s+\begin{bmatrix}\frac{dt^{2}}{2} & 0\\
0 & \frac{dt^{2}}{2}\\
dt & 0\\
0 & dt
\end{bmatrix}a=T_{s}s+T_{a}a$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $s'=\begin{bmatrix}x_{k+1}\\
y_{k+1}\\
x'_{k+1}\\
y'_{k+1}
\end{bmatrix}$
\end_inset

 and 
\begin_inset Formula $s=\begin{bmatrix}x_{k}\\
y_{k}\\
x'_{k}\\
y'_{k}
\end{bmatrix}$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\begin{cases}
x_{k+1}=x_{k}+x'_{k+1}dt+x''_{k+1}\frac{dt^{2}}{2} & +\mathcal{N}(0,\sigma_{x})\\
y_{k+1}=y_{k}+y'_{k+1}dt+y''_{k+1}\frac{dt^{2}}{2} & +\mathcal{N}(0,\sigma_{y})\\
x'_{k+1}=x'_{k}+x''_{k}dt & +\mathcal{N}(0,\sigma_{x'})\\
y'_{k+1}=y'_{k}+y''_{k}dt & +\mathcal{N}(0,\sigma_{y'})
\end{cases}$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
POMCP: MCTS with POMDP
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\series bold
\begin_inset Graphics
	filename img/BasicPOMCP-experimental_ttc1.png
	lyxscale 20
	scale 20

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 3
status open

\begin_layout Plain Layout
shrink=20
\end_layout

\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
POMCP: MCTS with POMDP
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{columns}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{column}{0.45
\backslash
textwidth}
\end_layout

\begin_layout Plain Layout


\backslash
Function{SelectAction}{$b,d$} 
\end_layout

\begin_layout Plain Layout

	
\backslash
State $h 
\backslash
gets 
\backslash
emptyset$
\end_layout

\begin_layout Plain Layout

	
\backslash
Loop
\end_layout

\begin_layout Plain Layout

		
\backslash
State $s 
\backslash
sim b$
\end_layout

\begin_layout Plain Layout

		
\backslash
State 
\backslash
Call {Simulate}{$s,h,d$}
\end_layout

\begin_layout Plain Layout

	
\backslash
EndLoop
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return arg max$_a
\backslash
text{ }Q(h,a)$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{column}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{column}{0.45
\backslash
textwidth}
\end_layout

\begin_layout Plain Layout


\backslash
Function{Simulate}{$s,h,d$} 
\end_layout

\begin_layout Plain Layout

	
\backslash
If {$d=0$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State 
\backslash
Return $0$
\end_layout

\begin_layout Plain Layout

	
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	
\backslash
State $a 
\backslash
gets 
\backslash
text{arg max}_a
\backslash
text{ }Q(h,a)+c
\backslash
sqrt{
\backslash
frac{logN(h)}{N(h,a)}}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $(s',o,r) 
\backslash
sim G(s,a)$
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	
\backslash
State $o_{class}, ttc 
\backslash
gets 
\backslash
Call {ClusterizeObs}{$s',o$}$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	
\backslash
If {$hao_{class} 
\backslash
notin T$}
\end_layout

\begin_layout Plain Layout

		
\backslash
For {$a 
\backslash
in A(s)$}
\end_layout

\begin_layout Plain Layout

			
\backslash
State $(N(h,a),Q(h,a)) 
\backslash
gets (N_0(h,a),Q_0(h,a))$
\end_layout

\begin_layout Plain Layout

		
\backslash
EndFor
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

		
\backslash
State $o_{class}^{id}  = o_{class}, o_{class}^{ttc} = ttc, o_{class}^{raw}
 = o$
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		
\backslash
State $T=T 
\backslash
cup 
\backslash
{hao_{class}
\backslash
}$
\end_layout

\begin_layout Plain Layout

		
\backslash
State 
\backslash
Return 
\backslash
Call {Rollout}{$s,d,
\backslash
pi_0$}
\end_layout

\begin_layout Plain Layout

	
\backslash
ElsIf {ttc $< o_{class}^{ttc}$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State $o_{class}^{ttc} = ttc, o_{class}^{raw} = o$
\end_layout

\begin_layout Plain Layout

	
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	
\backslash
State $q 
\backslash
gets r+
\backslash
lambda$ 
\backslash
Call {Simulate}{$s',hao_{class},d-1$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State $N(h,a) 
\backslash
gets N(h,a)+1$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $Q(h,a) 
\backslash
gets Q(h,a)+ 
\backslash
frac{q-Q(h,a)}{N(h,a)}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return $q$ 
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{column}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{column}{0.45
\backslash
textwidth}
\end_layout

\begin_layout Plain Layout


\backslash
Function{ClusterizeObs}{$s', o$} 
\end_layout

\begin_layout Plain Layout

	
\backslash
State $ttc 
\backslash
gets 
\backslash
Call {SmallestTimeToCollision}{$s',o$}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $o_{class} = floor(min(ttc, 11))$
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return $o_{class}, ttc$
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
Function{Rollout}{$b,d,
\backslash
pi_0$} 
\end_layout

\begin_layout Plain Layout

	
\backslash
If {$d=0$}
\end_layout

\begin_layout Plain Layout

		
\backslash
State 
\backslash
Return $0$
\end_layout

\begin_layout Plain Layout

	
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

	
\backslash
State $a 
\backslash
sim 
\backslash
pi_0(b)$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $s 
\backslash
sim b$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $(s',o,r) 
\backslash
sim G(s,a)$
\end_layout

\begin_layout Plain Layout

	
\backslash
State $b' 
\backslash
gets 
\backslash
Call {UpdateBelief}{$b,a,o$}$
\end_layout

\begin_layout Plain Layout

	
\backslash
State 
\backslash
Return $r+
\backslash
lambda$ 
\backslash
Call {Rollout}{$b',d-1,
\backslash
pi_0$}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{column}
\end_layout

\begin_layout Plain Layout


\backslash
end{columns}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Frame

\end_layout

\begin_layout Frame

\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Decision Making under Uncertainty for Urban Driving
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Paper: 
\begin_inset CommandInset href
LatexCommand href
name "AA228 Final Project"
target "https://web.stanford.edu/class/aa228/reports/2018/final100.pdf"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Demo: 
\begin_inset CommandInset href
LatexCommand href
name "online demo"
target "https://github.com/PhilippeW83440/ACT"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Benchmark results
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% Collisions
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Time To Goal
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hard Breaking
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
policy_v0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Policy TTC
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11.8 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
policy_v2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11.8 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
policy POMDP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12.8 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Frame

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
References
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "dmu"

\end_inset


\end_layout

\end_deeper
\end_body
\end_document
